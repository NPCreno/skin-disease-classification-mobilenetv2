{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m \n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "import os\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.applications.densenet import preprocess_input\n",
    "\n",
    "import shutil\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#for classification report\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "#for anomaly detection\n",
    "from tensorflow.lite.python import interpreter as interpreter_wrapper\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU ACTIVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the CUDA installation directory\n",
    "cuda_path = \"/usr/local/cuda\"  # Modify this path if necessary\n",
    "\n",
    "# Set the environment variables for CUDA\n",
    "os.environ[\"CUDA_HOME\"] = cuda_path\n",
    "os.environ[\"PATH\"] = os.environ[\"PATH\"] + \":\" + cuda_path + \"/bin\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = cuda_path + \"/lib64\"\n",
    "\n",
    "# Specify which GPU devices to use (optional)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Set to \"0,1\" to use multiple GPUs\n",
    "\n",
    "# Test if CUDA is available\n",
    "import tensorflow as tf\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"CUDA is successfully activated!\")\n",
    "else:\n",
    "    print(\"CUDA is not available or not properly configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET DIRECTORY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input  # Preprocessing function\n",
    "\n",
    "# Set paths\n",
    "train_path = r'D:\\EDUCATION FILES\\fifth year\\Thesis\\REVISION FOR MAIN OBJECTIVE\\1 SUPER FINAL\\Final dataset 11\\Train'\n",
    "valid_path = r'D:\\EDUCATION FILES\\fifth year\\Thesis\\REVISION FOR MAIN OBJECTIVE\\1 SUPER FINAL\\Final dataset 11\\Validation'\n",
    "test_path = r'D:\\EDUCATION FILES\\fifth year\\Thesis\\REVISION FOR MAIN OBJECTIVE\\1 SUPER FINAL\\Final dataset 11\\Test'\n",
    "\n",
    "# Set image preprocessing parameters\n",
    "input_size = (224, 224)\n",
    "train_batch_size = 32\n",
    "valid_batch_size = 32\n",
    "test_batch_size = 32\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  # Use the model's preprocessing function\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],  # Vary brightness between 80% and 120%\n",
    "    channel_shift_range=30  # Randomly shift channel values by up to 30\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  # Use the model's preprocessing function\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)  # Ensure consistency in preprocessing\n",
    "\n",
    "# Prepare the data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=input_size,\n",
    "    batch_size=train_batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=input_size,\n",
    "    batch_size=valid_batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=input_size,\n",
    "    batch_size=test_batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# Set image preprocessing parameters\n",
    "input_size = (224, 224)\n",
    "train_batch_size = 32\n",
    "valid_batch_size = 32\n",
    "test_batch_size = 32\n",
    "\n",
    "# Load MobileNetV2 model pre-trained on ImageNet\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "def create_model(base_model):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)  # L2 regularization\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l1(0.01))(x)  # L1 regularization\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01))(x)  # Both L1 and L2 regularization\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    preds = Dense(6, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=base_model.input, outputs=preds)\n",
    "    return model\n",
    "\n",
    "model = create_model(base_model)\n",
    "\n",
    "loss = 'categorical_crossentropy'\n",
    "learning_rate = 0.0001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduling\n",
    "def learning_rate_scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(learning_rate_scheduler)\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify the path to the dataset directory\n",
    "dataset_directory = r'D:\\EDUCATION FILES\\fifth year\\Thesis\\REVISION FOR MAIN OBJECTIVE\\1 SUPER FINAL\\Final dataset 11'\n",
    "\n",
    "# Create an empty dictionary to store classifier counts\n",
    "classifier_counts = {}\n",
    "\n",
    "# Define the subfolders\n",
    "subfolders = ['Train', 'Validation', 'Test']\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(dataset_directory, subfolder)\n",
    "    classifiers = os.listdir(subfolder_path)\n",
    "    \n",
    "    # Iterate through each classifier\n",
    "    for classifier in classifiers:\n",
    "        classifier_path = os.path.join(subfolder_path, classifier)\n",
    "        \n",
    "        # Count the number of images in the classifier folder\n",
    "        image_count = len([file for file in os.listdir(classifier_path) if os.path.isfile(os.path.join(classifier_path, file))])\n",
    "        \n",
    "        # Update the classifier counts dictionary\n",
    "        if classifier not in classifier_counts:\n",
    "            classifier_counts[classifier] = 0\n",
    "        classifier_counts[classifier] += image_count\n",
    "\n",
    "# Create a pie chart for all classifiers with total image counts and percentages\n",
    "labels = list(classifier_counts.keys())\n",
    "sizes = list(classifier_counts.values())\n",
    "colors = plt.cm.Paired(range(len(labels)))\n",
    "total_images = sum(sizes)\n",
    "percentages = [(size / total_images) * 100 for size in sizes]\n",
    "\n",
    "# Prepare labels for the pie chart with total images and percentages\n",
    "labels_with_count = [\"{} ({})\".format(labels[i], sizes[i]) for i in range(len(labels))]\n",
    "labels_with_percentage = [\"{} ({:.1f}%)\".format(labels[i], percentages[i]) for i in range(len(labels))]\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.pie(sizes, labels=labels_with_percentage, colors=colors, startangle=90, autopct='%1.1f%%')\n",
    "plt.legend(labels_with_count, loc=\"best\")\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title(\"Dataset Distribution by Classifier\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# Define the number of samples per class. Ensure that the class labels are accurate and correspond to the order in your data.\n",
    "samples_per_class = {\n",
    "   \"atopic\": 746,\n",
    "     \"benign_melanoma\": 800,\n",
    "     \"malignant_melanoma\": 927,\n",
    "     \"psoriasis\": 2883,\n",
    "     \"tinea\": 685,\n",
    "     \"unknown\": 1230\n",
    " }\n",
    "\n",
    "# samples_per_class = {\n",
    "#     \"benign_melanoma\": 800,\n",
    "#     \"malignant_melanoma\": 928,\n",
    "#     \"psoriasis\": 2469,\n",
    "#     \"tinea\": 761,\n",
    "#     \"unknown\": 1492\n",
    "# }\n",
    "\n",
    "# Calculate the total number of samples.\n",
    "total_samples = sum(samples_per_class.values())\n",
    "\n",
    "# Compute the class weights.\n",
    "class_weights = {class_label: (1 / num_samples) * (total_samples) / len(samples_per_class) \n",
    "                 for class_label, num_samples in samples_per_class.items()}\n",
    "\n",
    "# If your training generator uses categorical encoding, you might need to map the class names to their respective indices.\n",
    "label_to_index = {label: index for index, label in enumerate(samples_per_class.keys())}\n",
    "\n",
    "# Map the class weights to the respective class indices.\n",
    "class_weight_indices = {label_to_index[label]: weight for label, weight in class_weights.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIT THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "import datetime\n",
    "\n",
    "# ... [rest of your imports and model definition]\n",
    "\n",
    "# TensorBoard callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Early stopping definition\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "# Reduce learning rate on plateau definition\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.000001)\n",
    "\n",
    "# Train the model with the callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=200,  # You can increase this if you want, EarlyStopping will take care of halting the training if needed.\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator),\n",
    "    class_weight=class_weight_indices,\n",
    "    callbacks=[tensorboard_callback, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "import datetime\n",
    "\n",
    "# ... [rest of your imports and model definition]\n",
    "\n",
    "# TensorBoard callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "print(\"TensorBoard logs will be saved in:\", log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the data directory for the test dataset\n",
    "test_path = r'D:\\EDUCATION FILES\\fifth year\\Thesis\\REVISION FOR MAIN OBJECTIVE\\1 SUPER FINAL\\Final dataset 11\\Test'\n",
    "\n",
    "# Preprocess the test images\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size= test_batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_steps = (test_generator.n + test_batch_size - 1) // test_batch_size  # Calculate the correct number of steps\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_steps)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test data\n",
    "test_generator.reset()  # Reset the generator\n",
    "predictions = model.predict(test_generator, steps=test_steps)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true classes\n",
    "true_classes = test_generator.classes[:len(predicted_classes)]\n",
    "\n",
    "# Generate the classification report\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate predictions for the test data\n",
    "test_generator.reset()  # Reset the generator\n",
    "predictions = model.predict(test_generator, steps=test_steps)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true classes\n",
    "true_classes = test_generator.classes[:len(predicted_classes)]\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Display the confusion matrix as an image with numbers\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "\n",
    "# Add numbers to the confusion matrix\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = r'D:\\EDUCATION FILES\\fifth year\\Thesis\\REVISION FOR MAIN OBJECTIVE'\n",
    "\n",
    "# Save the entire model (including architecture, weights, and optimizer state)\n",
    "model.save(os.path.join(save_directory, 'Final dataset 11 (.92 test).h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model (\"Final dataset 11 (.92 test).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "print(\"model converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "with open('Final dataset 11 (.92 test).tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVE HIGH LOSS VALUE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_directory = 'E:\\FILES\\Thesis\\practice\\Datasets\\Additional Datasets\\From internet'\n",
    "\n",
    "# # Save the entire model (including architecture, weights, and optimizer state)\n",
    "# model.save(os.path.join(save_directory, 'dataset 10 (.94 test).h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobilenetv2_skinDisease",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
